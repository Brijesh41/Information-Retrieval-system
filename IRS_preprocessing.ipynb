{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IRS_preprocessing.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jZkm-eItEssW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1574744368238,"user_tz":-330,"elapsed":6342,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"755804ad-3476-4f2b-b823-f45feccd0a36"},"source":["pip install wordcloud"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.17.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O5S_7eDhE-wW","colab_type":"code","colab":{}},"source":["from nltk.stem import PorterStemmer\n","from nltk.tokenize import sent_tokenize,word_tokenize\n","import nltk\n","from nltk.corpus import stopwords"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WL4QNxNFa2r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1574745806209,"user_tz":-330,"elapsed":759,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"1edbf92d-e333-48e5-a548-bd3e1765ece0"},"source":["nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"pyJAh-1ZFhST","colab_type":"code","colab":{}},"source":["text = 'Spectral images tend to differ from normal images in terms of number of channel i.e when you look at a normal image it has three channels i.e RGB(Red,Green,Blue) and it is visible. While a hyperspectral image contains a number of bands(or Channels can be used interchangeably) . We will look into some of the datasets which are available on the internet and try to visualize those images. In addition to this, We will look into machine learning and deep learning algorithms which can be applied to the Indian Pines Data Set. Most of these images are gathered using AVIRIS(Airborne Visible/Infrared Imagining Spectrometer) Sensor.Let’s Look at some of the terms frequently used in Hyperspectral Images Bands : Earlier i mentioned about AVIRIS Sensor which has in particular 224 bands which means that images have a depth of 224. In addition to this these bands consists of visible, Near infrared,Ultraviolet, Short Infrared waves(SWIR), Difference between Multispectral images and Hyperspectral images: First of all in both of the images there are multiple bands involved but the major distinction lies in the narrowness of the bands, In case of multispectral images the bands are sparse compared to the hyperspectral images in which the images are very near and in some cases even overlapping. Talking about numbers there are ****And as Wikipedia perfects describes as “Multispectral imaging deals with several images at discrete and somewhat narrow bands”. '"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2VomxmQ2GDor","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1574745809735,"user_tz":-330,"elapsed":1380,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"0297792e-01a3-4d45-ff37-2b3aefd52006"},"source":["print(text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Spectral images tend to differ from normal images in terms of number of channel i.e when you look at a normal image it has three channels i.e RGB(Red,Green,Blue) and it is visible. While a hyperspectral image contains a number of bands(or Channels can be used interchangeably) . We will look into some of the datasets which are available on the internet and try to visualize those images. In addition to this, We will look into machine learning and deep learning algorithms which can be applied to the Indian Pines Data Set. Most of these images are gathered using AVIRIS(Airborne Visible/Infrared Imagining Spectrometer) Sensor.Let’s Look at some of the terms frequently used in Hyperspectral Images Bands : Earlier i mentioned about AVIRIS Sensor which has in particular 224 bands which means that images have a depth of 224. In addition to this these bands consists of visible, Near infrared,Ultraviolet, Short Infrared waves(SWIR), Difference between Multispectral images and Hyperspectral images: First of all in both of the images there are multiple bands involved but the major distinction lies in the narrowness of the bands, In case of multispectral images the bands are sparse compared to the hyperspectral images in which the images are very near and in some cases even overlapping. Talking about numbers there are ****And as Wikipedia perfects describes as “Multispectral imaging deals with several images at discrete and somewhat narrow bands”. \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jasKIMtMGEro","colab_type":"code","colab":{}},"source":["words = ''\n","tokens = []\n","for alphabet in text:\n","  if(alphabet == ' '):\n","    tokens.append(words)\n","    words = ''\n","  else:\n","    words = words + alphabet\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HNv9itN-GPpI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1574745813700,"user_tz":-330,"elapsed":1504,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"4e8f702f-3fe4-4e0e-e537-35ef60b4c405"},"source":["print(tokens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Spectral', 'images', 'tend', 'to', 'differ', 'from', 'normal', 'images', 'in', 'terms', 'of', 'number', 'of', 'channel', 'i.e', 'when', 'you', 'look', 'at', 'a', 'normal', 'image', 'it', 'has', 'three', 'channels', 'i.e', 'RGB(Red,Green,Blue)', 'and', 'it', 'is', 'visible.', 'While', 'a', 'hyperspectral', 'image', 'contains', 'a', 'number', 'of', 'bands(or', 'Channels', 'can', 'be', 'used', 'interchangeably)', '.', 'We', 'will', 'look', 'into', 'some', 'of', 'the', 'datasets', 'which', 'are', 'available', 'on', 'the', 'internet', 'and', 'try', 'to', 'visualize', 'those', 'images.', 'In', 'addition', 'to', 'this,', 'We', 'will', 'look', 'into', 'machine', 'learning', 'and', 'deep', 'learning', 'algorithms', 'which', 'can', 'be', 'applied', 'to', 'the', 'Indian', 'Pines', 'Data', 'Set.', 'Most', 'of', 'these', 'images', 'are', 'gathered', 'using', 'AVIRIS(Airborne', 'Visible/Infrared', 'Imagining', 'Spectrometer)', 'Sensor.Let’s', 'Look', 'at', 'some', 'of', 'the', 'terms', 'frequently', 'used', 'in', 'Hyperspectral', 'Images', 'Bands', ':', 'Earlier', 'i', 'mentioned', 'about', 'AVIRIS', 'Sensor', 'which', 'has', 'in', 'particular', '224', 'bands', 'which', 'means', 'that', 'images', 'have', 'a', 'depth', 'of', '224.', 'In', 'addition', 'to', 'this', 'these', 'bands', 'consists', 'of', 'visible,', 'Near', 'infrared,Ultraviolet,', 'Short', 'Infrared', 'waves(SWIR),', 'Difference', 'between', 'Multispectral', 'images', 'and', 'Hyperspectral', 'images:', 'First', 'of', 'all', 'in', 'both', 'of', 'the', 'images', 'there', 'are', 'multiple', 'bands', 'involved', 'but', 'the', 'major', 'distinction', 'lies', 'in', 'the', 'narrowness', 'of', 'the', 'bands,', 'In', 'case', 'of', 'multispectral', 'images', 'the', 'bands', 'are', 'sparse', 'compared', 'to', 'the', 'hyperspectral', 'images', 'in', 'which', 'the', 'images', 'are', 'very', 'near', 'and', 'in', 'some', 'cases', 'even', 'overlapping.', 'Talking', 'about', 'numbers', 'there', 'are', '****And', 'as', 'Wikipedia', 'perfects', 'describes', 'as', '“Multispectral', 'imaging', 'deals', 'with', 'several', 'images', 'at', 'discrete', 'and', 'somewhat', 'narrow', 'bands”.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5DEBZKRnHeZ9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1574745815115,"user_tz":-330,"elapsed":904,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"f642eadf-e94d-430b-f846-175a9fad6273"},"source":["print(len(tokens))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["232\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aldL2vyzHmQq","colab_type":"code","colab":{}},"source":["from nltk.stem import PorterStemmer\n","from nltk.tokenize import sent_tokenize,word_tokenize\n","import nltk\n","from nltk.corpus import stopwords"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nuXqBiwWH7LS","colab_type":"code","colab":{}},"source":["Stopwords = set(stopwords.words('english'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjOujmQuHrto","colab_type":"code","colab":{}},"source":["tokens = [word for word in tokens if word not in Stopwords]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yhQYli98IHok","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1574745821720,"user_tz":-330,"elapsed":1098,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"b57d66f9-a1c6-413b-f0ff-374ca269a0e7"},"source":["print(len(tokens))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["133\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X087MxtkKRxe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1574745824413,"user_tz":-330,"elapsed":1185,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"b6e505e8-149d-4c63-a01c-660eafca708a"},"source":["print(tokens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Spectral', 'images', 'tend', 'differ', 'normal', 'images', 'terms', 'number', 'channel', 'i.e', 'look', 'normal', 'image', 'three', 'channels', 'i.e', 'RGB(Red,Green,Blue)', 'visible.', 'While', 'hyperspectral', 'image', 'contains', 'number', 'bands(or', 'Channels', 'used', 'interchangeably)', '.', 'We', 'look', 'datasets', 'available', 'internet', 'try', 'visualize', 'images.', 'In', 'addition', 'this,', 'We', 'look', 'machine', 'learning', 'deep', 'learning', 'algorithms', 'applied', 'Indian', 'Pines', 'Data', 'Set.', 'Most', 'images', 'gathered', 'using', 'AVIRIS(Airborne', 'Visible/Infrared', 'Imagining', 'Spectrometer)', 'Sensor.Let’s', 'Look', 'terms', 'frequently', 'used', 'Hyperspectral', 'Images', 'Bands', ':', 'Earlier', 'mentioned', 'AVIRIS', 'Sensor', 'particular', '224', 'bands', 'means', 'images', 'depth', '224.', 'In', 'addition', 'bands', 'consists', 'visible,', 'Near', 'infrared,Ultraviolet,', 'Short', 'Infrared', 'waves(SWIR),', 'Difference', 'Multispectral', 'images', 'Hyperspectral', 'images:', 'First', 'images', 'multiple', 'bands', 'involved', 'major', 'distinction', 'lies', 'narrowness', 'bands,', 'In', 'case', 'multispectral', 'images', 'bands', 'sparse', 'compared', 'hyperspectral', 'images', 'images', 'near', 'cases', 'even', 'overlapping.', 'Talking', 'numbers', '****And', 'Wikipedia', 'perfects', 'describes', '“Multispectral', 'imaging', 'deals', 'several', 'images', 'discrete', 'somewhat', 'narrow', 'bands”.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"spznZWl6IKCp","colab_type":"code","colab":{}},"source":["porter = PorterStemmer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tn6P_F30KNgc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1574745844275,"user_tz":-330,"elapsed":1515,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"adeb7275-e808-4b28-e27a-69e90df97bfd"},"source":["tokens = [porter.stem(word) for word in tokens]\n","tokens = list(set(tokens))\n","print(len(tokens))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["91\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b9ucVQpJKQKO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1574745852804,"user_tz":-330,"elapsed":1197,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"0e46cdcb-5391-415c-d268-3ae0862aa3b8"},"source":["print(tokens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['machin', 'multispectr', 'case', 'term', 'perfect', 'major', 'discret', 'bands(or', 'appli', 'while', 'learn', 'aviris(airborn', 'spars', 'addit', 'imagin', '224', 'rgb(red,green,blue)', 'even', 'internet', 'mention', 'compar', 'images.', 'particular', 'normal', 'bands”.', 'gather', 'lie', 'We', 'deal', ':', 'hyperspectr', 'number', 'imag', 'three', 'dataset', 'visible,', 'channel', 'visual', 'somewhat', 'waves(swir),', 'interchangeably)', 'distinct', 'spectrometer)', 'use', 'pine', 'talk', 'aviri', 'earlier', 'tri', 'bands,', 'band', 'In', 'narrow', 'images:', 'short', 'most', 'sever', 'algorithm', 'tend', 'describ', 'look', 'i.e', 'sensor', 'data', 'infrared,ultraviolet,', '224.', 'indian', 'this,', 'spectral', 'visible.', 'wikipedia', 'avail', 'set.', 'visible/infrar', 'overlapping.', 'frequent', '****and', 'depth', 'near', 'contain', '“multispectr', 'mean', 'involv', '.', 'differ', 'first', 'sensor.let’', 'consist', 'deep', 'infrar', 'multipl']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_QhvUcKdKsND","colab_type":"code","colab":{}},"source":["freq = {}\n","for i in tokens:\n","  if(i in freq):\n","    freq[i] = freq[i]+1\n","  else:\n","    freq[i] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7KmCai_OgIu","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nK-tff9xOKzI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1574746893161,"user_tz":-330,"elapsed":722,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"9ca5c026-ccbb-45c1-c7f5-14c465f97343"},"source":["print(freq)\n","gra = freq"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'machin': 1, 'multispectr': 1, 'case': 1, 'term': 1, 'perfect': 1, 'major': 1, 'discret': 1, 'bands(or': 1, 'appli': 1, 'while': 1, 'learn': 1, 'aviris(airborn': 1, 'spars': 1, 'addit': 1, 'imagin': 1, '224': 1, 'rgb(red,green,blue)': 1, 'even': 1, 'internet': 1, 'mention': 1, 'compar': 1, 'images.': 1, 'particular': 1, 'normal': 1, 'bands”.': 1, 'gather': 1, 'lie': 1, 'We': 1, 'deal': 1, ':': 1, 'hyperspectr': 1, 'number': 1, 'imag': 1, 'three': 1, 'dataset': 1, 'visible,': 1, 'channel': 1, 'visual': 1, 'somewhat': 1, 'waves(swir),': 1, 'interchangeably)': 1, 'distinct': 1, 'spectrometer)': 1, 'use': 1, 'pine': 1, 'talk': 1, 'aviri': 1, 'earlier': 1, 'tri': 1, 'bands,': 1, 'band': 1, 'In': 1, 'narrow': 1, 'images:': 1, 'short': 1, 'most': 1, 'sever': 1, 'algorithm': 1, 'tend': 1, 'describ': 1, 'look': 1, 'i.e': 1, 'sensor': 1, 'data': 1, 'infrared,ultraviolet,': 1, '224.': 1, 'indian': 1, 'this,': 1, 'spectral': 1, 'visible.': 1, 'wikipedia': 1, 'avail': 1, 'set.': 1, 'visible/infrar': 1, 'overlapping.': 1, 'frequent': 1, '****and': 1, 'depth': 1, 'near': 1, 'contain': 1, '“multispectr': 1, 'mean': 1, 'involv': 1, '.': 1, 'differ': 1, 'first': 1, 'sensor.let’': 1, 'consist': 1, 'deep': 1, 'infrar': 1, 'multipl': 1}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IO6eRNe1PL28","colab_type":"code","colab":{}},"source":["from wordcloud import WordCloud, STOPWORDS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xW5oO4jjOSvC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1595688421735,"user_tz":-330,"elapsed":1278,"user":{"displayName":"SHAH BRIJESH BHUPENDRAKUMAR","photoUrl":"","userId":"16258444177402261720"}},"outputId":"41388604-40b1-48c1-f14f-2fdd382dd04e"},"source":["plt.figure(figsize=(50,7),facecolor=None)\n","plt.xticks(rotation=90)\n","plt.bar(gra.keys(),gra.values(),color='g')\n","plt.show()\n","\n","\n","wordcloud = WordCloud(width = 800, height = 800, \n","                background_color ='white', \n","                stopwords = stopwords, \n","                min_font_size = 10).generate(text) \n","  \n","plt.figure(figsize = (8, 8), facecolor = None) \n","plt.imshow(wordcloud)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0e93bf3e763e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}]},{"cell_type":"code","metadata":{"id":"w99GwQl6Oeuu","colab_type":"code","colab":{}},"source":["+\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]}]}